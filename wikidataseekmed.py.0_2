"""
Wikidata医療用語抽出ツール
実行方法: 
  python medical_terms_extractor.py --small --limit 2000
  python medical_terms_extractor.py --medium --limit 5000
  python medical_terms_extractor.py --medium --limit 0  # 無制限
"""

from SPARQLWrapper import SPARQLWrapper, JSON
import pandas as pd
import time
from datetime import datetime
import os
import argparse

class MedicalTermsExtractor:
    def __init__(self):
        self.sparql = SPARQLWrapper("https://query.wikidata.org/sparql")
        self.sparql.setReturnFormat(JSON)
        self.sparql.addCustomHttpHeader("User-Agent", "MedicalTermsExtractor/1.0")
        
        # 小規模テスト用カテゴリー（主要5カテゴリー）
        self.small_test_categories = {
            'Q12136': '病気',
            'Q12140': '医薬品',
            'Q169872': '症状',
            'Q796194': '外科手術',
            'Q1059392': '医学検査',
        }
        
        # 中規模用カテゴリー（主要15カテゴリー）
        self.medium_test_categories = {
            'Q12136': '病気',
            'Q12140': '医薬品',
            'Q169872': '症状',
            'Q796194': '外科手術',
            'Q1059392': '医学検査',
            'Q8054': 'タンパク質',
            'Q7187': '遺伝子',
            'Q4936952': '解剖学的構造',
            'Q18123741': '感染症',
            'Q11173': '化学化合物',
            'Q2095549': '医療処置',
            'Q10876': '細菌',
            'Q808': 'ウイルス',
            'Q179661': '治療薬',
            'Q12139612': '医療機器',
        }
        
        # 大規模用カテゴリー（包括的なカテゴリー）
        self.large_test_categories = {
            # 疾患系
            'Q12136': '病気',
            'Q18123741': '感染症',
            'Q929833': '希少疾患',
            'Q18965518': '精神疾患',
            'Q18556609': '神経疾患',
            
            # 解剖学
            'Q4936952': '解剖学的構造',
            'Q24060765': '臓器',
            'Q28845870': '組織',
            'Q7644128': '細胞型',
            
            # 医薬品・治療
            'Q12140': '医薬品',
            'Q179661': '治療薬',
            'Q128581': '抗生物質',
            'Q206159': 'ワクチン',
            
            # 症状・徴候
            'Q169872': '症状',
            'Q1441305': '医学的徴候',
            
            # 生化学・分子生物学
            'Q7187': '遺伝子',
            'Q8054': 'タンパク質',
            'Q417841': 'タンパク質',
            'Q11173': '化学化合物',
            'Q59199015': '酵素',
            'Q178593': 'ホルモン',
            
            # 診断・検査
            'Q1059392': '医学検査',
            'Q55788567': '画像診断',
            'Q11190': 'バイオマーカー',
            
            # 医療処置
            'Q796194': '外科手術',
            'Q2095549': '医療処置',
            
            # 微生物・病原体
            'Q10876': '細菌',
            'Q808': 'ウイルス',
            'Q764': '真菌',
            'Q37763': '寄生虫',
            
            # 医療機器
            'Q12139612': '医療機器',
        }
        
    def fetch_terms_by_category(self, category_qid, category_name, limit=None):
        """
        指定カテゴリーの医療用語を取得
        limit=None の場合は無制限
        """
        print("\n" + "="*60)
        print("カテゴリー: " + category_name)
        print("="*60)
        
        # LIMIT句の構築
        limit_clause = ""
        if limit is not None and limit > 0:
            limit_clause = "LIMIT " + str(limit)
        
        query = """
        SELECT DISTINCT ?item ?enLabel ?jaLabel ?enDescription ?jaDescription 
               ?meshId ?icd10 ?icd9 ?snomedId ?umlsId
        WHERE {
          ?item wdt:P31/wdt:P279* wd:""" + category_qid + """ .
          
          ?item rdfs:label ?enLabel .
          FILTER(LANG(?enLabel) = "en")
          
          OPTIONAL {
            ?item rdfs:label ?jaLabel .
            FILTER(LANG(?jaLabel) = "ja")
          }
          
          OPTIONAL {
            ?item schema:description ?enDescription .
            FILTER(LANG(?enDescription) = "en")
          }
          
          OPTIONAL {
            ?item schema:description ?jaDescription .
            FILTER(LANG(?jaDescription) = "ja")
          }
          
          OPTIONAL { ?item wdt:P486 ?meshId }
          OPTIONAL { ?item wdt:P494 ?icd10 }
          OPTIONAL { ?item wdt:P493 ?icd9 }
          OPTIONAL { ?item wdt:P5806 ?snomedId }
          OPTIONAL { ?item wdt:P2892 ?umlsId }
        }
        """ + limit_clause
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                self.sparql.setQuery(query)
                results = self.sparql.query().convert()
                bindings = results["results"]["bindings"]
                
                terms = []
                for result in bindings:
                    term = {
                        'qid': result['item']['value'].split('/')[-1],
                        'category': category_name,
                        'category_qid': category_qid,
                        'en_label': result.get('enLabel', {}).get('value', ''),
                        'ja_label': result.get('jaLabel', {}).get('value', ''),
                        'en_description': result.get('enDescription', {}).get('value', ''),
                        'ja_description': result.get('jaDescription', {}).get('value', ''),
                        'mesh_id': result.get('meshId', {}).get('value', ''),
                        'icd10': result.get('icd10', {}).get('value', ''),
                        'icd9': result.get('icd9', {}).get('value', ''),
                        'snomed_id': result.get('snomedId', {}).get('value', ''),
                        'umls_id': result.get('umlsId', {}).get('value', ''),
                    }
                    terms.append(term)
                
                count_msg = "取得完了: " + str(len(terms)) + "件"
                print(count_msg)
                return terms
                
            except Exception as e:
                error_msg = "エラー (試行 " + str(attempt + 1) + "/" + str(max_retries) + "): " + str(e)
                print(error_msg)
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5
                    wait_msg = str(wait_time) + "秒待機..."
                    print(wait_msg)
                    time.sleep(wait_time)
                else:
                    fail_msg = "取得失敗: " + category_name
                    print(fail_msg)
                    return []
        
        return []
    
    def extract_all(self, categories, limit_per_category=None):
        """
        全カテゴリーの医療用語を抽出
        limit_per_category=None の場合は無制限
        """
        all_terms = []
        
        print("\n" + "="*60)
        cat_msg = "医療用語抽出開始: " + str(len(categories)) + "カテゴリー"
        print(cat_msg)
        if limit_per_category is None or limit_per_category == 0:
            print("各カテゴリー: 無制限")
        else:
            limit_msg = "各カテゴリー最大: " + str(limit_per_category) + "件"
            print(limit_msg)
        print("="*60)
        
        start_time = time.time()
        
        for qid, name in categories.items():
            terms = self.fetch_terms_by_category(qid, name, limit_per_category)
            all_terms.extend(terms)
            time.sleep(2)
        
        elapsed_time = time.time() - start_time
        
        print("\n" + "="*60)
        print("抽出完了")
        total_msg = "総取得件数: " + str(len(all_terms)) + "件"
        print(total_msg)
        time_msg = "所要時間: " + str(round(elapsed_time/60, 1)) + "分"
        print(time_msg)
        print("="*60 + "\n")
        
        df = pd.DataFrame(all_terms)
        
        original_count = len(df)
        df = df.drop_duplicates(subset=['qid'])
        duplicates_removed = original_count - len(df)
        
        if duplicates_removed > 0:
            dup_msg = "重複削除: " + str(duplicates_removed) + "件"
            print(dup_msg)
            unique_msg = "ユニーク件数: " + str(len(df)) + "件\n"
            print(unique_msg)
        
        return df
    
    def analyze_data_quality(self, df):
        """
        データ品質を分析
        """
        print("\n" + "="*60)
        print("データ品質分析")
        print("="*60 + "\n")
        
        print("1. 基本統計:")
        total_msg = "   総レコード数: " + str(len(df)) + "件"
        print(total_msg)
        unique_msg = "   ユニークQID: " + str(df['qid'].nunique()) + "件"
        print(unique_msg)
        
        print("\n2. 言語カバレッジ:")
        has_en = (df['en_label'].notna() & (df['en_label'] != '')).sum()
        has_ja = (df['ja_label'].notna() & (df['ja_label'] != '')).sum()
        en_msg = "   英語ラベルあり: " + str(has_en) + "件 (" + str(round(has_en/len(df)*100, 1)) + "%)"
        print(en_msg)
        ja_msg = "   日本語ラベルあり: " + str(has_ja) + "件 (" + str(round(has_ja/len(df)*100, 1)) + "%)"
        print(ja_msg)
        
        print("\n3. 説明文カバレッジ:")
        has_en_desc = (df['en_description'].notna() & (df['en_description'] != '')).sum()
        has_ja_desc = (df['ja_description'].notna() & (df['ja_description'] != '')).sum()
        en_desc_msg = "   英語説明あり: " + str(has_en_desc) + "件 (" + str(round(has_en_desc/len(df)*100, 1)) + "%)"
        print(en_desc_msg)
        ja_desc_msg = "   日本語説明あり: " + str(has_ja_desc) + "件 (" + str(round(has_ja_desc/len(df)*100, 1)) + "%)"
        print(ja_desc_msg)
        
        print("\n4. 外部IDカバレッジ:")
        external_ids = [
            ('mesh_id', 'MeSH'),
            ('icd10', 'ICD-10'),
            ('icd9', 'ICD-9'),
            ('snomed_id', 'SNOMED CT'),
            ('umls_id', 'UMLS')
        ]
        for col, name in external_ids:
            count = (df[col].notna() & (df[col] != '')).sum()
            ext_msg = "   " + name + ": " + str(count) + "件 (" + str(round(count/len(df)*100, 1)) + "%)"
            print(ext_msg)
        
        print("\n5. カテゴリー別件数:")
        category_counts = df['category'].value_counts().sort_values(ascending=False)
        for category, count in category_counts.items():
            cat_msg = "   " + category + ": " + str(count) + "件"
            print(cat_msg)
        
        print("\n6. 日英対訳可能な用語:")
        bilingual = df[(df['en_label'] != '') & (df['ja_label'] != '')]
        bi_msg = "   対訳ペア: " + str(len(bilingual)) + "件 (" + str(round(len(bilingual)/len(df)*100, 1)) + "%)"
        print(bi_msg)
        
        print("\n" + "="*60 + "\n")
        
        return bilingual
    
    def save_results(self, df, prefix="small"):
        """
        結果をCSVとJSON形式で保存
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = "output"
        
        os.makedirs(output_dir, exist_ok=True)
        
        print("結果を保存中...\n")
        
        # 1. 完全版CSV
        full_csv = output_dir + "/" + prefix + "_medical_terms_full_" + timestamp + ".csv"
        df.to_csv(full_csv, index=False, encoding='utf-8-sig')
        file_size_mb = os.path.getsize(full_csv) / (1024 * 1024)
        full_msg = "   完全版CSV: " + full_csv + " (" + str(round(file_size_mb, 2)) + " MB)"
        print(full_msg)
        
        # 2. 日英対訳のみCSV
        bilingual_df = df[(df['en_label'] != '') & (df['ja_label'] != '')].copy()
        bilingual_csv = output_dir + "/" + prefix + "_bilingual_dict_" + timestamp + ".csv"
        cols_to_save = ['en_label', 'ja_label', 'category', 'en_description', 'ja_description', 'qid']
        bilingual_df[cols_to_save].to_csv(bilingual_csv, index=False, encoding='utf-8-sig')
        file_size_mb = os.path.getsize(bilingual_csv) / (1024 * 1024)
        bi_msg = "   日英対訳CSV: " + bilingual_csv + " (" + str(len(bilingual_df)) + "件, " + str(round(file_size_mb, 2)) + " MB)"
        print(bi_msg)
        
        # 3. カテゴリー別CSV
        category_dir = output_dir + "/by_category_" + timestamp
        os.makedirs(category_dir, exist_ok=True)
        for category in df['category'].unique():
            cat_df = df[df['category'] == category]
            safe_name = category.replace('/', '_').replace('\\', '_')
            cat_file = category_dir + "/" + safe_name + ".csv"
            cat_df.to_csv(cat_file, index=False, encoding='utf-8-sig')
        cat_count = len(df['category'].unique())
        cat_msg = "   カテゴリー別CSV: " + category_dir + "/ (" + str(cat_count) + "ファイル)"
        print(cat_msg)
        
        # 4. JSON形式
        json_file = output_dir + "/" + prefix + "_medical_terms_" + timestamp + ".json"
        df.to_json(json_file, orient='records', force_ascii=False, indent=2)
        file_size_mb = os.path.getsize(json_file) / (1024 * 1024)
        json_msg = "   JSON: " + json_file + " (" + str(round(file_size_mb, 2)) + " MB)"
        print(json_msg)
        
        # 5. サマリーレポート
        report_file = output_dir + "/" + prefix + "_report_" + timestamp + ".txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("Wikidata医療用語抽出レポート\n")
            f.write("="*60 + "\n\n")
            f.write("実行日時: " + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + "\n")
            f.write("規模: " + prefix + "\n")
            f.write("総件数: " + str(len(df)) + "件\n")
            f.write("日英対訳: " + str(len(bilingual_df)) + "件\n")
            f.write("日英対訳率: " + str(round(len(bilingual_df)/len(df)*100, 1)) + "%\n\n")
            
            f.write("カテゴリー別件数:\n")
            for category, count in df['category'].value_counts().items():
                f.write("  " + category + ": " + str(count) + "件\n")
            
            f.write("\n言語カバレッジ:\n")
            has_ja = (df['ja_label'].notna() & (df['ja_label'] != '')).sum()
            ja_pct = round(has_ja/len(df)*100, 1)
            f.write("  日本語ラベルあり: " + str(has_ja) + "件 (" + str(ja_pct) + "%)\n")
            
            f.write("\n外部IDカバレッジ:\n")
            external_ids = [
                ('mesh_id', 'MeSH'),
                ('icd10', 'ICD-10'),
                ('snomed_id', 'SNOMED CT'),
                ('umls_id', 'UMLS')
            ]
            for col, name in external_ids:
                count = (df[col].notna() & (df[col] != '')).sum()
                pct = round(count/len(df)*100, 1)
                f.write("  " + name + ": " + str(count) + "件 (" + str(pct) + "%)\n")
        
        report_msg = "   レポート: " + report_file
        print(report_msg)
        
        print("\n保存完了！\n")
        
        return {
            'full_csv': full_csv,
            'bilingual_csv': bilingual_csv,
            'category_dir': category_dir,
            'json': json_file,
            'report': report_file
        }


def parse_arguments():
    """
    コマンドライン引数を解析
    """
    parser = argparse.ArgumentParser(
        description='Wikidata医療用語抽出ツール',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
使用例:
  小規模テスト（5カテゴリー、各2,000件）:
    python %(prog)s --small --limit 2000
  
  中規模テスト（15カテゴリー、各5,000件）:
    python %(prog)s --medium --limit 5000
  
  大規模テスト（30カテゴリー以上、無制限）:
    python %(prog)s --large --limit 0
  
  中規模テスト（無制限）:
    python %(prog)s --medium --limit 0
        """
    )
    
    # サイズオプション（相互排他的）
    size_group = parser.add_mutually_exclusive_group(required=True)
    size_group.add_argument(
        '--small',
        action='store_true',
        help='小規模テスト（5カテゴリー）'
    )
    size_group.add_argument(
        '--medium',
        action='store_true',
        help='中規模テスト（15カテゴリー）'
    )
    size_group.add_argument(
        '--large',
        action='store_true',
        help='大規模テスト（30+カテゴリー）'
    )
    
    # 件数制限オプション
    parser.add_argument(
        '--limit',
        type=int,
        default=2000,
        help='各カテゴリーの最大取得件数（0で無制限、デフォルト: 2000）'
    )
    
    # 対話モード無効化オプション
    parser.add_argument(
        '--no-interactive',
        action='store_true',
        help='対話モードをスキップして即座に実行'
    )
    
    return parser.parse_args()


def main():
    """
    メイン処理
    """
    # コマンドライン引数を解析
    args = parse_arguments()
    
    # サイズとprefixを決定
    if args.small:
        size_name = "small"
        size_label = "小規模"
        category_count = 5
    elif args.medium:
        size_name = "medium"
        size_label = "中規模"
        category_count = 15
    else:  # args.large
        size_name = "large"
        size_label = "大規模"
        category_count = "30+"
    
    # 制限の表示
    if args.limit == 0:
        limit_label = "無制限"
    else:
        limit_label = str(args.limit) + "件"
    
    print("""
╔══════════════════════════════════════════════════════════╗
║   Wikidata医療用語抽出ツール                             ║
╚══════════════════════════════════════════════════════════╝
    """)
    
    print("実行設定:")
    print("  規模: " + size_label + " (" + str(category_count) + "カテゴリー)")
    print("  各カテゴリー: " + limit_label)
    print("")
    
    # 推定時間を表示
    if args.small and args.limit <= 2000:
        est_time = "5-10分"
    elif args.medium and args.limit <= 5000:
        est_time = "30-60分"
    elif args.large or args.limit == 0:
        est_time = "数時間以上"
    else:
        est_time = "状況により変動"
    
    print("予想所要時間: " + est_time)
    print("")
    
    # 対話モードでない場合は確認をスキップ
    if not args.no_interactive:
        input("Enterキーを押して開始...")
    
    # Extractorを初期化
    extractor = MedicalTermsExtractor()
    
    # カテゴリーを選択
    if args.small:
        categories = extractor.small_test_categories
    elif args.medium:
        categories = extractor.medium_test_categories
    else:  # large
        categories = extractor.large_test_categories
    
    # 制限を設定（0の場合はNoneに変換）
    limit = None if args.limit == 0 else args.limit
    
    # データ抽出
    df = extractor.extract_all(categories, limit_per_category=limit)
    
    # データ品質分析
    bilingual_df = extractor.analyze_data_quality(df)
    
    # サンプル表示
    if len(bilingual_df) > 0:
        print("サンプルデータ（日英対訳あり、最初の5件）:")
        print("="*80)
        sample = bilingual_df[['en_label', 'ja_label', 'category']].head()
        for idx, row in sample.iterrows():
            en_part = row['en_label'][:30].ljust(30)
            ja_part = row['ja_label'][:20].ljust(20)
            cat_part = "[" + row['category'] + "]"
            sample_line = "  " + en_part + " -> " + ja_part + " " + cat_part
            print(sample_line)
        print("="*80 + "\n")
    
    # 結果保存
    files = extractor.save_results(df, prefix=size_name)
    
    print("""
╔══════════════════════════════════════════════════════════╗
║   抽出完了！                                              ║
╚══════════════════════════════════════════════════════════╝

次のステップ:
1. outputフォルダ内のCSVファイルを確認
2. データ品質を評価

規模を変更する場合:
  小規模: python """ + __file__ + """ --small --limit 2000
  中規模: python """ + __file__ + """ --medium --limit 5000
  大規模: python """ + __file__ + """ --large --limit 0
    """)


if __name__ == "__main__":
    main()